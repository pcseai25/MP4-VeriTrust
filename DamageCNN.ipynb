{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjCtoG241KoW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import cv2\n",
        "\n",
        "# Paths\n",
        "zip_file_path = \"/content/Undamage.zip\"\n",
        "extract_path = \"undamaged_dataset/\"\n",
        "\n",
        "# Step 1: Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# Step 2: Define directories\n",
        "train_dir = os.path.join(extract_path, 'train')  # Assume it contains 'damaged' and 'undamaged' folders\n",
        "validation_dir = os.path.join(extract_path, 'validation')\n",
        "\n",
        "# Step 3: Image data generator and preprocessing\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2, shear_range=0.2, zoom_range=0.2,\n",
        "                                   horizontal_flip=True, fill_mode='nearest')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Step 4: Create the train and validation generators\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(150, 150),\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(validation_dir,\n",
        "                                                              target_size=(150, 150),\n",
        "                                                              batch_size=32,\n",
        "                                                              class_mode='binary')\n",
        "\n",
        "# Step 5: Build the CNN model\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional and Pooling layers\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Dropout for regularization\n",
        "model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification\n",
        "\n",
        "# Step 6: Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Step 7: Train the model\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=20,\n",
        "                    validation_data=validation_generator)\n",
        "\n",
        "# Step 8: Save the model\n",
        "model.save(\"damaged_note_classifier.h5\")\n",
        "\n",
        "# Step 9: Evaluate the model\n",
        "validation_loss, validation_accuracy = model.evaluate(validation_generator)\n",
        "print(f'Validation accuracy: {validation_accuracy * 100:.2f}%')"
      ]
    }
  ]
}